\chapter{Przegląd stanu wiedzy}\label{chap:teoria}
\section{Uczenie maszynowe}\label{machine_learning}
Mówi się, że program komputerowy uczy się z doświadczenia (\textit{experience}) E w związku z pewną klasą zadań (\textit{tasks}) T oraz miarą wydajności (\textit{performance measure}) P jeżeli jego osiągi w zadaniach w T, jak mierzone przez P, ulegają polepszeniu z doświadczeniem E. \cite{mitchell1997machine}
W przypadku pojedynczej konwolucyjnej sieci neuronowej (opisanej bliżej w \ref{sec:cnn}):
\begin{itemize}
	\item jako doświadczenie $E_{CN}$ możemy zdefiniować przetwarzanie obrazów wraz z ich etykietami klas
	\item zadaniem $T_{CN}$ nazwiemy klasyfikację obrazów
	\item miarą jakości $P_{CN}$ będzie stosunek liczby poprawnie zaklasyfikowanych zdjęć ze zbioru testowego do wielkości zbioru testowego
\end{itemize}
W przypadku algorytmu genetycznego (opisanego w \ref{sec:ag}) poszukującego optymalnej struktury sieci neuronowej:
\begin{itemize}
	\item doświadczeniem $E_{GA}$ będzie tworzenie i testowanie nowych sieci neuronowych
	\item zadanie $T_{GA}$ to poszukiwanie optymalnej w sensie $P_{CN}$ struktury (parametrów) sieci neuronowej
	\item miarą jakości $P_{GA}$ będzie miara jakości najlepszego wygenerowanego przez algorytm osobnika
\end{itemize}
Zastosowanie jednego algorytmu z dziedziny uczenia maszynowego do poprawy procesu uczenia się innego algorytmu tej samej klasy ma ścisły związek z pojęciem metauczenia.
\section{Metauczenie}
\begin{enumerate}
	\item System metauczący się (\textit{A metalearning system}) musi zawierać podsystem uczący się, który przystosowuje się z doświadczeniem.
	\item Doświadczenie jest zdobywane poprzez wykorzystywanie metawiedzy wydobytej
	\begin{enumerate}[a)]
		\item z poprzedniego epizodu uczenia na pojedynczym zbiorze danych, i/lub
		\item z innych dziedzin lub problemów.
	\end{enumerate}
\end{enumerate}
Dodatkowo, często używanym pojęciem w metauczeniu jest pojęcie tendencyjności (\textit{bias}), które w tym kontekście odnosi się do zbioru założeń wpływających na wybór hipotez opisujących dane. \cite{Lemke2015}
Hipoteza w tym kontekście oznacza funkcję predykcyjną (\textit{predictive function}) powstałą w wyniku zastosowania tradycyjnego uczenia (np. konwolucyjnej sieci neuronowej) pewnymi danymi, a wpływ na jej kształt mają ustalone założenia zaszyte w strukturze uczonego algorytmu. \cite[s.2]{Brazdil2009}
Autorzy w \cite{Brazdil2009} wyróżniają:
\begin{itemize}
	\item tendencyjność deklaratywną (\textit{declarative bias}) - specyfikuje ona reprezentację przestrzeni hipotez, np. przedstawianie hipotez korzystając wyłącznie z sieci neuronowych
	\item tendencyjność proceduralną (\textit{procedural bias}) - wpływa na szeregowanie hipotez, np. preferowanie hipotez o krótszym czasie wykonania (\textit{runtime})
\end{itemize}
Zgodnie z tą teorią, w tradycyjnym uczeniu tendencyjność jest stała, podczas gdy metauczenie stara się ją dobierać dynamicznie. \cite{Lemke2015}
W kontekście projektowanego systemu automatycznie dobierającego parametry konwolucyjnej sieci neuronowej, spełnia ona założenia sprecyzowane w pierwszej części definicji, tj.
\begin{itemize}
	\item Istnieje uczący się podsystem (konwolucyjna sieć neuronowa)
	\item Struktura najlepszego osobnika ulega zmianie (przystosowuje się z doświadczeniem)
	\item Metawiedza jest wydobywana z poprzednich epizodów uczenia (jako wartość funkcji przystosowania konkretnej struktury)
\end{itemize}
W odniesieniu do tendencyjności deklaratywnej - przestrzeń poszukiwań (najlepszego algorytmu do klasyfikacji obrazów) została zawężona wyłącznie do konwolucyjnych sieci neuronowych, jednakże sieci o różnych strukturach będą produkować różne hipotezy.
Poszukiwanie najlepszego algorytmu do klasyfikacji obrazów na zbiorze CIFAR-10 nie jest tematem tej pracy - jest nią próba znalezienia optymalnej struktury dla konkretnego algorytmu.
W przypadku tak zawężonej przestrzeni poszukiwań dalej możemy preferować jedne generowane hipotezy od drugich, co można regulować odpowiednio modyfikując funkcję przystosowania, np. uwzględniając karę za komplikację uzyskanej struktury (np. wynikowa ilość aktywnych warstw konwolucyjnych).
\section{Uczenie z nadzorem}\label{supervised_learning}
Zadanie uczenia maszynowego nauczenia się funkcji wiążącej wejście z wyjściem na podstawie przykładowych par wejściowo-wyjściowych nazywamy uczeniem z nadzorem. \cite{russell2010artificial}
Polega ono na wywodzeniu funkcji z oznaczonych etykietami danych treningowych składających się ze zbioru przykładów treningowych. \cite{mohri2012foundations}
Przykładowy problem, który może zostać zaklasyfikowany do uczenia z nadzorem: posiadając historyczne dane miesięczne na temat ilości pożarów w danym mieście, przewidzieć ile pożarów wybuchnie w nadchodzącym miesiącu.
W tym wypadku czas (miesiąc) jest zmienną niezależną, a liczba pożarów zmienną zależną. Ustalenie związku pomiędzy tymi wielkościami (znalezienie modelu) jest zadaniem regresji, które jest jedną z podklas uczenia z nadzorem.
Drugą klasą takich problemów jest tzw. problem klasyfikacji, w którym, zamiast wyznaczać funkcję, której zbiór wartości jest (w przybliżeniu) ciągły, identyfikujemy odwzorowane, które pozwoli nam nową, nieznaną daną zakwalifikować do dyskretnego zbioru klas.
Popularnym przykładem jest uczenie systemu klasyfikowania wiadomości e-mail jako spam lub nie, gdy posiadamy zbiór treningowy w postaci już opisanych jako należące do odpowiedniej klasy wiadomości.
Podczas gdy taki klasyfikator (filtr antyspamowy) przetwarza tekst, w przypadku niniejszej pracy magisterskiej mamy do czynienia z problemem klasyfikacji obrazów.
\section{Klasyfikacja obrazów}
Klasyfikacja obrazów jest zadaniem z klasy uczenia z nadzorem, w którym poszukujemy funkcji przypisującej obrazom odpowiednie etykiety z pewnego skończonego zbioru.
Jest to jeden z podstawowych problemów przetwarzania obrazów.
Co więcej, wiele pozornie różnych zadań (takich jak detekcja obiektów, segmentacja) można zredukować do problemu klasyfikacji obrazów.
Przykładowo, model klasyfikujący obrazy przetwarza zdjęcie pokazane poniżej na rys. \ref{fig:image_classification} i przypisuje prawdopodobieństwa do czterech kategorii, $\lbrace kot, pies, kapelusz, kubek \rbrace$.
Jak pokazano na rysunku, należy pamiętać, że zdjęcia dla komputera są niczym innym jak dużą trójwymiarową tablicą liczb.
W tym przypadku zdjęcie kota jest szerokie na 2048 pikseli, wysokie na 1536 pikseli i posiada 3 kanały koloru: czerwony, zielony i niebieski (z ang. w skrócie \textit{RGB}).
Tym samym zdjęcie składa się z $2048 \times 1536 \times 3 = 9437184$ liczb.

\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 1.0\linewidth]{img/kot}
	 \caption{Komputerowa reprezentacja zdjęcia kota \\
              Źródło: praca własna na podstawie \cite{cs231n}}
	 \label{fig:image_classification}
\end{figure}

Zadanie klasyfikacji obrazów w tym przypadku polega na zredukowaniu tych prawie 10 milionów liczb do jednej etykiety, dla rys. \ref{fig:image_classification} będzie to ''$kot$''.
Dla człowieka rozpoznanie obiektu jest względnie proste. Z punktu widzenia algorytmu przetwarzania obrazów napotykamy kilka zasadniczych trudności, związanych z faktem, że komputer interpretuje obraz jako trójwymiarową macierz wartości jasności pikseli:
\begin{itemize}
	\item Zróżnicowanie perspektywy - ten sam obiekt może być różnie zorientowany względem kamery rejestrującej obraz
	\item Zróżnicowanie skali - obiekty jednej klasy (np. koty) często występują w różnych rozmiarach (nie tylko z punktu widzenia rozmiaru na zdjęciu, ale i w rzeczywistości)
	\item Deformacja - wiele klasyfikowanych obiektów nie jest bryłami sztywnymi i mogą być skrajnie zniekształcone
	\item Okluzja - zjawisko zasłonięcia obiektu przez inny obiekt, czasem jedynie niewielki fragment szukanego obiektu jest widoczny
	\item Warunki oświetleniowe - efekty różnego oświetlenia są bardzo wydatne na poziomie pikseli
	\item Nieład w tle - klasyfikowane obiekty mogą zlewać się z tłem, czyniąc ich identyfikację trudniejszą
	\item Zróżnicowanie wewnątrz klasy - niektóre klasy są bardzo ogólne (np. broń) i zawierają w sobie bardzo różnie wyglądające obiekty (np. miecz a karabin maszynowy).
\end{itemize}
Na rys.\ref{fig:classification_problems} przedstawiono ilustrację powyższych problemów.

\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 1.0\linewidth]{img/klas_problemy}
	 \caption{Problemy w klasyfikacji obrazów \\
              Źródło: praca własna na podstawie \cite{cs231n}}
	 \label{fig:classification_problems}
\end{figure}

Dobry model klasyfikujący obrazy powinien być niewrażliwy na dowolne kombinacje powyższych zakłóceń, jednocześnie pozostając wrażliwym na zróżnicowanie pomiędzy klasami.
Stworzenie algorytmu poprawnie klasyfikującego obrazy jest zadaniem nietrywialnym (w przeciwieństwie np. do ułożenia algorytmu sortującego liczby według zadanego porządku).
Jednym ze podejść, jakie można przyjąć do tego problemu, jest stworzenie algorytmu, który będzie się uczył na podstawie dużej ilości oznaczonych etykietami danych, czyli wspomniane wcześniej uczenie maszynowe (\ref{machine_learning}) i uczenie z nadzorem (\ref{supervised_learning}).
Takie rozwiązanie problemu nazywane jest również podejściem opartym na danych (\textit{data-driven approach}).
\cite{cs231n}


\section{CIFAR-10}
Przykładem zbioru danych służącego do uczenia i oceny algorytmów uczenia maszynowego w dziedzinie klasyfikacji obrazów jest zbiór CIFAR-10.
Zbiór danych CIFAR-10 składa się z 60000 kolorowych obrazków o wymiarach 32x32 pogrupowanych w 10 klas, po 6000 obrazków w każdej. Zbiór treningowy składa się z 50000 obrazków, a testowy z 10000.

Dane zorganizowane są w pięć partii treningowych i jedną testową, po 10000 obrazków każda. Partia testowa zawiera dokładnie po 1000 losowo wybranych obrazków z każdej klasy. Partie treningowe zawierają pozostałe obrazki w losowej kolejności, w związku z czym niektóre partie mogą zawierać więcej obrazków z jednej klasy niż pozostałych. Łącznie zawierają po 5000 obrazków z każdej klasy.

Poniżej, na rysunku \ref{fig:sample_data} przedstawiono wszystkie klasy wraz z 10 losowymi obrazkami dla każdej z nich.
\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 1.0\linewidth]{img/sample_images}
	 \caption{Przykładowe obrazki ze zbioru CIFAR-10 \\
              Źródło: https://www.cs.toronto.edu/\textasciitilde kriz/cifar.html}
	 \label{fig:sample_data}
\end{figure}

Każda z klas wyklucza się wzajemnie. Klasy ''samochód'' (\textit{automobile}) i ''ciężarówka'' (\textit{truck}) nie posiadają części wspólnej. ''Samochód'' zawiera sedany, SUVy i inne tego typu samochody. ''Ciężarówka'' zawiera tylko duże ciężarówki. Żadna z nich nie zawiera pojazdów typu pickup.

Poniżej opisano organizację tego zbioru danych w wersji dla języka Python.

Archiwum zawiera pliki data\_batch1, data\_batch2 data\_batch5, jak również test\_batch. Każdy z tych plików jest poddaną serializacji wersją obiektu Pythonowego wytworzonego za pomocą cPickle. Poniżej, na listingu \ref{lst:read_data} przedstawiono procedurę odczytującą te pliki i zwracającą słownik dla Pythona w wersji 2:

\begin{lstlisting}[caption={Procedura ładowania zbioru danych},label={lst:read_data},language=Python,captionpos=b,frame=single]
def unpickle(file):
    import cPickle
    with open(file, 'rb') as fo:
        dict = cPickle.load(fo)
    return dict
\end{lstlisting}

    Załadowane w ten sposób, każdy z plików z partiami zawiera następujące elementy:
\begin{itemize}
\item \textit{data} - macierz \textit{numpy} typu \textit{uint8} o wymiarach 10000x3072. Każdy rząd macierzy przechowuje kolorowy obrazek o wymiarach 32x32. Pierwsze 1024 pozycji zawiera wartości pikseli dla kanału czerwonego, kolejne 1024 dla zielonego, a ostatnie dla niebieskiego. Zdjęcia przechowywane są rzędami w kolejności od góry do dołu, tj. pierwsze 32 elementy macierzy opisują wartości kanału czerwonego dla pierwszego rzędu pikseli obrazka.
\item \textit{labels} - lista 10000 liczb w przedziale 0-9. Liczba pod indeksem i oznacza etykietę z klasą dla i-tego obrazka w macierzy data.
\end{itemize}

Zbiór danych zawiera również plik batches.meta, który również zawiera obiekt typu słownik dla języka Python. Zawiera on następujące elementy:
\begin{itemize}
\item \textit{label\_names} - 10-elementowa lista która nadaje czytelne dla człowieka nazwy liczbowym etykietom w liście \textit{labels} opisanej powyżej. Na przykład, label\_names[0] == ''airplane'', label\_names[1] == ''automobile'', itd. \cite{Krizhevsky09learningmultiple}
\end{itemize}

Wśród kilku podejść, które mogą nam posłużyć do rozwiązania tego problemu, wyróżnić możemy algorytm k najbliższych sąsiadów (\textit{k - Nearest Neighbor Classifier}), klasyfikatory liniowe, sieci neuronowe.

\section{K najbliższych sąsiadów}\label{sec:knear}

Dla zbioru CIFAR-10 mamy $50000$ obrazków oznaczonych etykietami i $10000$ obrazów, które chcemy zaklasyfikować.
Każdy obrazek o wymiarach $32 \times 32 \times 3$ możemy przedstawić jako wektor o wymiarach $3072 \times 1$.
Oznacza to, że każdy z nich możemy interpretować jako punkt w przestrzeni $3072$-wymiarowej.
Najprostszym sposobem w jaki możemy klasyfikować nowe dane jest badanie ich położenia w owej przestrzeni.
Zakładając, że obrazki jednej klasy będą grupować się w klastry, każdy kolejny punkt znajdujący się blisko chmury punktów reprezentującej daną klasę z wysokim prawdopodobieństwem również będzie przynależał do tej klasy.
Przykładowo, rozważmy sytuację jak na rys. \ref{fig:knearest} dla klasyfikacji dwuwymiarowych punktów. Punkt albo przynależy do klasy 'niebieski okrąg', albo 'czerwony krzyżyk'. Rozważamy punkt, który oznaczony jest zielonym krzyżykiem.

\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 1.0\linewidth]{img/knear}
	 \caption{Ilustracja działania algorytmu k najbliższych sąsiadów w dwóch wymiarach \\
              Źródło: praca własna}
	 \label{fig:knearest}
\end{figure}

Dla najprostszego przypadku $k=1$ badamy odległości (w tym przypadku używając normy $l^2$) pomiędzy interesującym nas punktem a wszystkimi danymi ze zbioru treningowego i przyjmujemy, że badany punkt będzie przynależał do tej samej klasy, do której przynależy jej najbliższy sąsiad.
W przypadku rys. \ref{fig:knearest} badany zielony punkt znajduje się najbliżej czerwonego krzyżyka w punkcie $(0,-1)$, zatem przypisujemy go do tej samej klasy.
Dla większych wartości k rozważamy więcej najbliższych sąsiadów i przypisujemy rozważany punkt do tej klasy, do której należy większość najbliższych punktów.

Podejście to, mimo iż intuicyjne i proste w implementacji, nie rozwiązuje dobrze problemu klasyfikacji, osiągając skuteczność $39.6\%$ dla $k = 1$ dla zbioru CIFAR-10.
Jest to lepiej niż losowe przydzielanie do klas (które dla 10 klas ma skuteczność $10\%$), ale wciąż dalekie od skuteczności człowieka.

Jednym z problemów podejścia k najbliższych sąsiadów jest kosztowne testowanie nowych punktów.
Dla każdego nowego punktu wymaga ono policzenia odległości od 50000 punktów w przestrzeni 3072-wymiarowej oraz posortowania wg. obliczonej odległości, co jest dość kosztowną operacją.

Kolejnym problemem w przypadku przetwarzania obrazów jest klasyfikowanie wyłącznie na podstawie dominujących w obrazie wartości kolorów.
Na przykład, zarówno w przypadku klasy ''samolot'' jak i w przypadku klasy ''statek'' często występującym w tle kolorem będzie niebieski, gdyż niebieskie jest zarówno niebo i woda.
Tak duże podobieństwo może prowadzić do błędnej klasyfikacji w przypadku tych dwóch klas. \cite{cs231n}

\section{Klasyfikator liniowy}\label{sec:linear_classifier}

Innym podejściem, jakie można przyjąć do klasyfikacji obrazów, jest stworzenie liniowego odwzorowania pomiędzy pikselową reprezentacją obrazu a stopniem przynależności danego obrazu do poszczególnych klas.
Oznaczając dane treningowe przez $x_i \in R^D$, każde powiązane z etykietą $y_i$.
W tym przypadku $i = 1 ... N$ i $y_i \in 1 ... K$, tj. zbiór uczący składa się z $N$ przykładów (każdy D-wymiarowy) i K rozróżnialnych kategorii.
Przykładowo, dla zbioru CIFAR-10 zbiór treningowy ma rozmiar $N = 50000$, każdy po $32 \times 32 \times 3 = 3072$ pikseli i $K = 10$, ponieważ rozróżniamy pomiędzy 10 klasami (pies, kot, samochód itd.).
Zdefiniujemy funkcję oceny (\textit{score function}) $f : R^D \mapsto R^K$, która odwzorowuje wartości pikseli do oceny przynależności do danej klasy.
Zatem liniowy klasyfikator zdefiniować jako następujące liniowe odwzorowanie:
\begin{equation}\label{eqn:lc}
f(x_i,W,b) = Wx_i + b
\end{equation}
We wzorze \ref{eqn:lc} zakładamy, że obrazek $x_i$ zawiera wszystkie wartości swoich pikseli w wektorze o wymiarach $[D \times 1]$.
Macierz $W$ (o wymiarach $[K \times D$]) oraz wektor $b$ (o wymiarach [$K \times 1$]) są parametrami funkcji.
W zbiorze CIFAR-10 $x_i$ zawiera wszystkie piksele $i$-tego obrazka spłaszczone do jednej [$3072 \times 1$] kolumny, $W$ ma wymiar [$10 \times 3072$] a $b$ [$10 \times 1$], zatem 3072 liczby są wejściem dla funkcji, a wyjść jest 10 (oceny klas).
Parametry wewnątrz $W$ nazywane są również wagami, a wektor $b$ nazywany jest wektorem przesunięcia (\textit{bias vector}), ponieważ ma wpływ na wyjściowe oceny bez wchodzenia w interakcję z danymi $x_i$. \cite{cs231n}

Jak już wspominano, obrazki mogą być rozumiane jako punkty w 3072 wymiarowej przestrzeni.
Pojedynczy liniowy klasyfikator możemy interpretować jako hiperpłaszczyznę separującą punkty w tej przestrzeni.
Możemy wyobrazić sobie ściśnięcie wszystkich punktów do dwóch wymiarów jak na rys. \ref{fig:cartoon_class}, wtedy hiperpłaszczyzny sprowadzają się do prostych.

\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 0.75\linewidth]{img/klas_cartoon}
	 \caption{Schematyczna wizualizacja działania klasyfikatorów liniowych \\
              Źródło: praca własna na podstawie \cite{cs231n}}
	 \label{fig:cartoon_class}
\end{figure}

Przy klasyfikatorze liniowym warto zauważyć kilka faktów:
\begin{itemize}
	\item Pojedyncze mnożenie macierzowe $Wx_i$ w efekcie wyznacza oceny dla 10 różnych klasyfikatorów jednocześnie (jeden na klasę), gdzie każdy klasyfikator to rząd macierzy W i jednej prostej separującej na rys. \ref{fig:cartoon_class}
	\item Dane wejściowe $(x_i,y_i)$ są ustalone, a kontrolujemy parametry $W,b$. Naszym celem będzie ustawienie tych parametrów w taki sposób, by wynikowe oceny zgadzały się z prawdziwymi przynależnościami do klas na całym zbiorze treningowym.
	\item Zaletą tego podejścia jest możliwość odrzucenia (nie przechowywania w pamięci) zbioru treningowego po nauczeniu się parametrów $W,b$. Dzieje się tak, ponieważ nowe punkty do klasyfikacji klasyfikujemy przy pomocy ocen uzyskanych z już nauczonej funkcji.
	\item Klasyfikowanie obrazów testowych sprowadza się do pojedynczego mnożenia macierzowego i dodawania, które jest szybsze od porównywania do wszystkich obrazków ze zbioru treningowego (jak w \ref{sec:knear}).
\end{itemize}

Przykład mapowania wartości pikseli do oceny przynależności do klas przedstawiono na rys. \ref{fig:lin_class}
\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 1.0\linewidth]{img/lin_klas}
	 \caption{Mapowanie 4 monochromatycznych pikseli do 3 klas \\
              Źródło: praca własna na podstawie \cite{cs231n}}
	 \label{fig:lin_class}
\end{figure}

Jak widać na rys. \ref{fig:lin_class}, wagi w macierzy W nie są dobrze dobrane, gdyż klasyfikator przypisuje najwyższą ocenę klasie pies, podczas gdy w istocie na obrazku znajduje się kot.
Uczenie liniowego klasyfikatora będzie polegać na takim doborze wag, by błędy klasyfikacji zachodziły jak najrzadziej.
W tym celu zdefiniujemy funkcję kosztów (\textit{loss function}), która będzie miarą tego jak dobrze działa dany klasyfikator.\cite{cs231n}

Funkcję kosztów dla całego zbioru danych definiuje wzór \ref{eqn:total_loss}.
\begin{equation}\label{eqn:total_loss}
L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{składowa danych} + \underbrace{ \lambda R(W) }_\text{składowa regularyzacji} \\\\
\end{equation}
gdzie $\lambda$ jest parametrem kontrolującym oddziaływanie regularyzacji przy uczeniu, $L_i$ wartością funkcji kosztu dla pojedynczego obrazka przy ustalonych wagach W (wzór \ref{eqn:single_loss_svm} lub \ref{eqn:single_loss_softmax}).
Składowa regularyzacji penalizuje duże wagi w macierzy $W$ i w tym przypadku będzie definiowana jako norma $l^2$ dla tej macierzy, zgodnie ze wzorem \ref{eqn:regularization}.

\begin{equation}\label{eqn:regularization}
R(W) = \sum_k\sum_l W_{k,l}^2
\end{equation}

Wprowadzenie tej składowej do funkcji kosztu pozwala uniknąć niejednoznaczności rozwiązania, gdzie dowolna macierz $W$ przeskalowana o współczynnik $\alpha \in R^+$ jest równie dobrym rozwiązaniem.
W ten sposób preferowane będą rozwiązania o o mniejszych wartościach współczynników.
Co więcej, okazuje się, że przy takim podejściu uzyskujemy lepiej generalizujące i bardziej odporne na nadmierne dopasowanie (\textit{overfitting}) klasyfikatory.
Wynika to z faktu, że żaden z wejściowych wymiarów nie może mieć dużego wpływu na końcowy wynik.
Dla przykładu, dla wektora danych $x = [1,1,1,1]$ i dwóch wektorów wagowych $w_1 = [1,0,0,0]$ i $w_2 = [0.25,0.25,0.25,0.25]$ wynik mnożenia (wartość funkcji oceny) $w_1^Tx = w_2^Tx = 1$.
Jednakże wprowadzenie kary $l^2$ do funkcji kosztu powoduje, że preferowany będzie wektor $w_2$, gdyż $||w_2|| < ||w_1||$, a naszym celem jest minimalizacja funkcji kosztów.
Widać zatem, że preferowane będą wektory wagowe o bardziej rozłożonych współczynnikach.

Składowa danych ze wzoru \ref{eqn:total_loss} jest funkcją kosztu dla pojedynczego obrazka uśrednioną po wszystkich danych treningowych.
Dla $i$-tego punktu treningowego możemy zdefiniować wiele różnych funkcji kosztu.
Dla klasyfikatora typu wieloklasowa maszyna wektorów nośnych (\textit{Multiclass SVM}) będzie to koszt ''zawiasowy'' (\textit{hinge loss}, wzór \ref{eqn:single_loss_svm}), natomiast dla klasyfikatora typu \textit{Softmax} koszt entropii krzyżowej (\textit{cross-entropy loss}, przedstawiony na wzorze \ref{eqn:single_loss_softmax}).
\begin{equation}\label{eqn:single_loss_svm}
L_i = \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + \Delta)
\end{equation}
gdzie $s_j = f(x_i, W)_j$ to $j$-ty element wektora ocen klas, $s_{y_i}$ jest oceną uzyskaną przez prawdziwą klasę, a $\Delta$ jest marginesem, który chcemy utrzymać pomiędzy wartością oceny klasy prawdziwej a wartościami ocen klas niepoprawnych.

\begin{equation}\label{eqn:single_loss_softmax}
L_i = -\log\left(\frac{e^{s_{y_i}}}{ \sum_j e^{s_j} }\right) \hspace{0.5in} \text{lub równoważnie} \hspace{0.5in} L_i = -s_{y_i} + \log\sum_j e^{s_j}
\end{equation}
gdzie $s_j$ jak wyżej oznacza $j$-ty element wektora ocen klas $s$, tutaj interpretowany jako nieznormalizowany logarytm prawdopodobieństwa przynależności do danej klasy.

Możemy teraz znaleźć taką macierz wagową $W$, która minimalizuje wartość przyjętej funkcji kosztu, tym samym maksymalizując poprawność działania klasyfikatora.
Jest to problem optymalizacji, który rozwiązujemy najczęściej przy pomocy gradientowych metod optymalizacji, np. metody najszybszego spadku. \cite{cs231n}

Powodem, dla którego tyle miejsca poświęcono liniowemu klasyfikatorowi i pojęciami z nim związanymi jest fakt, że wszystkie te pojęcia mają również zastosowanie przy sieciach neuronowych.

\section{Sieci Neuronowe}\label{sec:nn}

\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 1.0\linewidth]{img/neuron}
	 \caption{Pojedynczy 3-wejściowy neuron \\
              Źródło: praca własna na podstawie \cite{cs231n,zuradabarskijedruch1996}}
	 \label{fig:neuron}
\end{figure}

Zarówno zwierzęta, jak i ludzie lepiej radzą sobie z rozpoznawaniem obrazów niż współczesne komputery.
Sieci neuronowe dlatego wzbudzają zainteresowanie, że możemy za ich pomocą częściowo naśladować ludzki mózg.
Informacja w takich sieciach przetwarzana jest przez dużą ilość węzłów obliczeniowych oraz połączeń między nimi.
Skoordynowane jednostki jednocześnie dokonują przetwarzania wszystkich lub większości sygnałów i danych wejściowych.
Działanie sztucznych sieci neuronowych możemy porównać do rozproszonych systemów obliczeniowych.
Elementarną jednostkę wykonującą obliczenia w takiej sieci nazywamy neuronem.
Pojedynczy neuron dokonuje sumowania i nieliniowego przetwarzania sygnałów.
Nierzadko możemy je przyrównać do elementów działających progowo, aktywujących się w momencie przekroczenia pewnego zadanego progu przez sumę sygnałów na wejściu.
Często neurony organizowane są w regularne struktury, zwykle możemy w owych strukturach wyróżnić poszczególne warstwy.
Możliwe jest występowanie połączeń zwrotnych pomiędzy neuronami tej samej warstwy lub z różnych warstw.
Każde połączenie pomiędzy neuronami charakteryzowane jest przez siłę jego oddziaływania zwaną również wagą. \cite{zuradabarskijedruch1996}

Schematycznie pojedynczy neuron możemy przedstawić jak na rys. \ref{fig:neuron}

Pojedynczy neuron możemy również traktować jako klasyfikator liniowy, stąd obszerniejszy opis klasyfikatorów liniowych w \ref{sec:linear_classifier}.
Matematyczny model neuronu od linowego klasyfikatora różni się jedynie zastosowaniem nieliniowości po operacji iloczynu skalarnego.
Nieliniowość owa odpowiada za zdolność neuronu do preferowania pewnych liniowych obszarów jego wejścia (wartość funkcji aktywacji w okolicy 1) od innych (wartość funkcji aktywacji w okolicy 0).
Tym samym stosując odpowiednią postać funkcji kosztu możemy sprowadzić zwykły neuron do klasyfikatora liniowego. \cite{cs231n}

Architektura sieci jest tym co odróżnia konkretne sieci od siebie.
Na przykład sieci nie posiadające połączeń zwrotnych reagują na pobudzenie w sposób natychmiastowy i te właśnie sieci będą omawiane w dalszej części pracy.
Natomiast sieci, które posiadają połączenia zwrotne, ustalają swoją odpowiedź dopiero po pewnym czasie, mają zatem swoją dynamikę określające ich zachowanie w czasie. \cite{zuradabarskijedruch1996}
Dalej rozważać będziemy jedynie sieci bez połączeń zwrotnych.

Sieci neuronowe posiadają wiele zastosowań, wśród nich można wymienić:
\begin{itemize}
	\item modelowanie zagadnień programowania liniowego
	\item rozpoznawanie pisma
	\item zastosowania w teorii sterowania
	\begin{itemize}
		\item identyfikacja obiektów
		\item neurosterowanie obiektami statycznymi
	\end{itemize}
	\item sterowanie kinematyką robotów
	\item neuronowe sieci ekspertowe \cite{zuradabarskijedruch1996}
\end{itemize}

Pytanie o to, które z modyfikowalnych komponentów systemu uczącego się są odpowiedzialne za jego sukces lub porażkę i jakie zmiany w nich polepszają ich wydajność nazywane jest fundamentalnym problemem przypisania zasługi (\textit{the fundamental credit assignment problem}). \cite{SCHMIDHUBER201585}.
Innymi słowy do dziś nie wiadomo, co dokładnie jest czynnikiem sprawiającym, że jedna sieć będzie działać lepiej od drugiej.
Badanie czy algorytm genetyczny jest w stanie poprawić jakość działania takiej sieci jest częściowo próbą znalezienia odpowiedzi na to pytanie.

\section{Konwolucyjne sieci neuronowe}\label{sec:cnn}

Konwolucyjne sieci neuronowe (\textit{Convolutional Neural Networks}) są podobne do opisanych w \ref{sec:nn} sieci neuronowych.
Tworzone są z neuronów, które posiadają swoje wagi, które zmieniają się w wyniku procesu uczenia.
Każdy z neuronów otrzymuje sygnały na wejściu, dokonuje ich sumowania, a następnie może dokonać nieliniowego odwzorowania.
Cała sieć wyraża pojedynczą, różniczkowalną funkcję odwzorowującą wartości jasności pikseli do zbioru klas.
Sieci te projektowane są z założeniem, że będą przetwarzały obrazy, stąd ich specyficzna architektura, która zostanie opisana poniżej.

Motywacją stojącą za poszukiwaniem innych architektur sieci neuronowych była bardzo szybko narastająca ilość wag do uczenia w przypadku przetwarzania obrazów za pomocą w pełni połączonych sieci neuronowych.
Biorąc dla przykładu CIFAR-10 i obrazki o wymiarach $ 32 \times 32 \times 3$ (wysokość, szerokość, 3 kanały kolorów), pojedynczy neuron znajdujący się zaraz za warstwą wejściową posiadałby 3072 + 1 wejście od stałej wartości (\textit{bias}) wag do nauczenia.
Dla tak małych obrazków liczba ta nie wydaje się być problematyczna, jednak podając na wejście obraz o wymiarach $1024 \times 768 \times 3 = 2359296$ widzimy, że już pojedynczy neuron zaczyna zajmować bardzo dużo pamięci.
Zakładając, że każda waga przechowywana jest jako liczba zmiennoprzecinkowa o podwójnej precyzji i przechowywana w 8 bajtach, uzyskujemy $18874368$ B $= 18$MB na jeden neuron.
Tak duża liczba parametrów jest nadmiarowa i może prowadzić do nadmiernego dopasowania.

Konwolucyjne sieci neuronowe wykorzystują fakt, że danymi podawanymi na ich wejście są obrazy i nakładają ograniczenia na architekturę w bardziej rozsądny sposób.
W szczególności, w przeciwieństwie do tradycyjnej sieci neuronowej, warstwy sieci konwolucyjnej posiadają neurony zorganizowane w 3 wymiarach: wysokości, szerokości i głębokości (rozumianej jako trzeci wymiar wejścia, nie jako głębokość w sensie liczby warstw w sieci).
W sieciach neuronowych każda warstwa przekształca trójwymiarowe wejście na trójwymiarowe wyjście przez różniczkowalną funkcję, która może lecz nie musi posiadać parametry.

W sieciach konwolucyjnych wyróżnia się kilka podstawowych rodzajów warstw, które następnie składa się w całą sieć.
Trzy podstawowe typy to:
\begin{itemize}
	\item warstwa konwolucyjna lub splotowa - oblicza wyjścia neuronów połączonych z lokalnymi fragmentami wejścia, wyznaczając iloczyn skalarny pomiędzy swoimi wagami a małym obszarem wejścia, do którego są połączone.
	\item warstwa agregująca - dokonuje operacji podpróbkowania (\textit{subsampling}) wzdłuż wysokości i szerokości wejścia, zmniejszając wymiar danych na swoim wyjściu
	\item warstwa w pełni połączona - tak jak w klasycznych sieciach neuronowych, każdy neuron jest połączony z każdą jednostką wejścia
\end{itemize}

Przyjmować będziemy również, że warstwa aktywacji liniowej (\textit{ReLU, Rectified Linear Unit}) jest ''zaszyta'' wewnątrz warstwy konwolucyjnej, na jej wyjściu.
Warstwa ta realizuje funkcję $max(0, x)$ w odniesieniu do każdego elementu na swoim wejściu. \cite{cs231n}
Schematycznie organizację neuronów w konwolucyjnej sieci neuronowej przedstawiono na rys. \ref{fig:cnn}

\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 1.0\linewidth]{img/cnn}
	 \caption{Schematyczne przedstawienie architektury konwolucyjnej sieci neuronowej \\
              Źródło: \cite{cs231n}}
	 \label{fig:cnn}
\end{figure}

Na rysunku uwidoczniona została główna idea konwolucyjnych sieci neuronowych - najważniejszy parametr to liczba neuronów w warstwie, zwana również głębokością warstwy, która w tym przypadku wynosi 5.
Każdy z tych neuronów posiada swój zestaw wag, który następnie jest splatany z obrazem wejściowym na całej jego szerokości i wysokości.
Owe 5 filtrów ''widzi'' tylko swój mały kawałek obrazu, nazywany jego polem percepcji (\textit{receptive field}).
Takie ograniczenie nazywane jest lokalną połączeniowością (\textit{local connectivity}).
W wyniku operacji splotu otrzymywana jest mapa cech dla każdego neuronu, i w wyniku procesu uczenia neurony dobierają swoje wagi tak, by być wrażliwymi na cechy charakterystyczne dla danej klasy.
Oprócz liczby filtrów z różnymi wagami, z których każdy splatany jest przez na zasadzie ruchomego okna, dodatkowymi parametrami cechującymi taką sieć są:

\begin{itemize}
	\item przeskok (\textit{stride}) - okno można przesuwać konsekwentnie piksel po pikselu po całym obrazie, można jednak przesuwać o większą ilość pikseli, owocuje to jednak zmniejszeniem wymiaru obrazu wyjściowego
	\item dopełnianie zerami (\textit{zero padding}) - w przypadku skrajnych pikseli okno np. o wymiarach 3x3 przesuwane jest po nieistniejących w obrazie pikselach, które najczęściej zastępowane są zerami.
	 			Rozmiar ramki złożonej z zer jest parametrem, który pozwala nam kontrolować rozmiar wyjścia.
\end{itemize}

Rozmiar obrazu po przejściu przez warstwę tak zdefiniowaną można obliczyć ze wzoru \ref{eqn:output_size}

\begin{equation}\label{eqn:output_size}
(W - F + 2P)/S + 1
\end{equation}
gdzie W to wymiary obrazu wejściowego, F to rozmiar pola percepcji neuronu, P to liczba dopełnianych zer a S to przeskok z jakim przesuwamy okno.

Co do warstwy agregującej, również wykonuje ona operacje na małym polu wejściowym, dając w wyniku jeden skalar - np. z pola 2x2 wybierana jest maksymalna wartość lub średnia ważona wszystkich wartości.
Operacja taka ma na celu zwiększenie kontroli nad nadmiernym dopasowaniem przez algorytm, i w wyniku daje pomniejszony wymiar obrazu (mapy) wyjściowej, np. przeprowadzenie agregacji 2x2 na warstwie 32x32 zaowocuje obrazem o wymiarach 16x16 na wyjściu.

Warstwa w pełni połączona zazwyczaj używana jest na końcu i zwykle znajduje się w niej tyle neuronów, ile klas, a ich wyjście mówi nam (w przypadku zastosowaniu odpowiedniej funkcji kosztu przy uczeniu sieci) o prawdopodobieństwie przynależenia danego obrazka do danej klasy.

Spośród wymienionych wyżej parametrów, kontrolowanym przez algorytm genetyczny parametrem będzie głębokość 4 warstw.

\section{Algorytm genetyczny}\label{sec:ag}

Algorytm genetyczny jest kolejnym opisywanym narzędziem sztucznej inteligencji, które powstało dzięki obserwacji natury i jej sposobów działania.
Wywodzi się on z genetyki, czyli z badania dziedziczności i zmienności organizmów.
Pierwsze badania z tej dziedziny w XIX wieku przeprowadzał Gregor Johann Mendel.
W ich wyniku powstało pojęcie genu - abstrakcyjnej jednostki dziedziczności oraz alleli - różnych odmian tego samego genu.
Dalej możemy mówić o chromosomach, czyli strukturach znajdujących się wewnątrz jąder komórek zwierzęcych i roślinnych, które zawierają geny.
Chromosomy zbudowane są z kwasu dezoksyrybonukleinowego (DNA), które koduje całą informację genetyczną danego osobnika.
Na podstawie obserwacji sposobu dziedziczenia i rozmnażania się komórek, procesu ewolucji zaproponowano algorytm genetyczny, który w istocie jest stochastyczną metodą optymalizacji, jak przedstawiono na rys. \ref{fig:klas_opt}.

\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 0.8\linewidth]{img/optymalizacja}
	 \caption{Podział metod optymalizacji \\
              Źródło: \cite{bialaszewski2012}}
	 \label{fig:klas_opt}
\end{figure}

Podstawowe cechy algorytmu genetycznego:
\begin{enumerate}
	\item poszukiwania prowadzone są w wielu punktach
	\item zadanie optymalizacji sparametryzowane w sposób zakodowany
	\item nowe rozwiązania tworzone i wybierane są przy pomocy metod probabilistyczno-ewolucyjnych
	\item brak ograniczeń na przestrzeń poszukiwań - funkcja celu może być dowolna, nieznana \label{lst:opt}
	\item prostota implementacji i uniwersalność
\end{enumerate}

Głównie ze względu na punkt \ref{lst:opt} wybrano tę metodę do optymalizacji struktury konwolucyjnych sieci neuronowych, gdyż funkcja skuteczności sieci w zależności od jej struktury jest nieznana.

Istotnymi pojęciami w AG są pojęcia genotypu i fenotypu.
Genotyp rozumiemy jako zakodowane parametry reprezentujące danego osobnika.
Poniżej wymieniono kilka podstawowych sposobów kodowania parametrów w AG:
\begin{itemize}
	\item bialleliczne
	\item Gray’a
	\item logarytmiczne
	\item trialleliczne
	\item multialleliczne
	\item wielopoziomowe
	\item całkowitoliczbowe
\end{itemize}
Fenotyp jest uzewnętrznieniem tych zakodowanych cech.

Podstawowe operacje algorytmu genetycznego zwane operacjami genetycznymi oraz kilka ich realizacji wymieniono poniżej:
\begin{itemize}
	\item selekcja:
	\begin{itemize}
		\item metodą proporcjonalną
		\item metodą ze stochastycznym doborem resztowym
		\item metodą turniejową
		\item metodą rangową
		\item metodą progową
	\end{itemize}
	\item krzyżowanie (pominięto sposoby krzyżowania dla kodowania całkowitoliczbowego)
	\begin{itemize}
		\item jednopunktowe
		\item wielopunktowe
		\item jednorodne (równomierne)
		\item arytmetyczne
		\item mieszane
	\end{itemize}
	\item mutacja:
	\begin{itemize}
		\item genotypowa
		\item fenotypowa
		\begin{itemize}
			\item równomierna
			\item nierównomierna
		\end{itemize}
		\item inwersja
		\item wstawianie
		\item przenoszenie
		\item wzajemna wymiana
	\end{itemize}
	\item podstawienie:
	\begin{itemize}
		\item reprodukcja pełna
		\item reprodukcja częściowa
		\begin{itemize}
			\item usuwanie najgorszych osobników - elityzm
			\item usuwanie najbardziej podobnych do potomstwa osobników - metoda ze ściskiem
			\item usuwanie losowo wybranych osobników
		\end{itemize}
	\end{itemize}
\end{itemize} \cite{bialaszewski2012}

Algorytm genetyczny początkowo wytwarza losową populację osobników (rozwiązań).
Następnie dla każdego z osobników wyznaczana jest wartość funkcji przystosowania, która ma być zmaksymalizowana.
Następnie, spośród ocenionych już osobników wybierana jest pula rodzicielska przy pomocy jednej z metod selekcji.
Wewnątrz wybranej puli rodzicielskiej z pewnym prawdopodobieństwem nazywanym prawdopodobieństwem krzyżowania dochodzi do krzyżowania, czyli powstania dwóch nowych potomków z dwóch rodziców.
Następnie, wszystkie osobniki z pewnym prawdopodobieństwem zwanym prawdopodobieństwem mutacji są modyfikowane.
Ostatecznie, całość lub część starej populacji jest wymieniana według jednej ze strategii reprodukcji.
Powyższe działania powtarzane są tak długo, aż nie otrzymamy satysfakcjonującego nas rozwiązania, np. rozwiązanie nie poprawi się przez 100 kolejnych iteracji.
Działanie algorytmu genetycznego można schematycznie przedstawić jak na rysunku \ref{fig:gen_schemat}

\begin{figure}[h!tb]
	 \centering
	 \includegraphics[width = 1.0\linewidth]{img/genetyczny_schemat}
	 \caption{Schemat działania algorytmu genetycznego \\
              Źródło: praca własna}
	 \label{fig:gen_schemat}
\end{figure}
